library(httr)
library(jsonlite)
library(dplyr)
library(digest)

# Definir cabeçalhos
headers <- c(
  'X-API-KEY' = '6e8a10b98341bd1dc5c9a2c1ef01e2d65f589cdd',
  'Content-Type' = 'application/json'
)

# Definir a lista de termos de busca
search_terms <- c("clusterização"
                  #,"Bill Gates"
                  )

# Função para buscar a primeira página (sem o parâmetro de paginação)
fetch_first_page <- function(query) {
  body <- list(
    q = query,
    gl = "br",
    hl = "pt-br"
  )
  
  res <- VERB("POST", url = "https://google.serper.dev/scholar", body = toJSON(body), add_headers(headers))
  
  # Verifica se a requisição foi bem-sucedida
  if (status_code(res) != 200) {
    stop("Request failed with status: ", status_code(res))
  }
  
  response_text <- content(res, 'text')
  response_json <- fromJSON(response_text)
  
  # Verifica se há resultados
  if (length(response_json$organic) == 0) {
    return(NULL)
  }
  
  results_df <- as.data.frame(response_json$organic)
  return(results_df)
}

# Função para buscar resultados de páginas subsequentes (com paginação)
fetch_results <- function(query, page_num) {
  body <- list(
    q = query,
    gl = "br",
    hl = "pt-br",
    page = page_num
  )
  
  res <- VERB("POST", url = "https://google.serper.dev/scholar", body = toJSON(body), add_headers(headers))
  
  # Verifica se a requisição foi bem-sucedida
  if (status_code(res) != 200) {
    stop("Request failed with status: ", status_code(res))
  }
  
  response_text <- content(res, 'text')
  response_json <- fromJSON(response_text)
  
  # Verifica se há resultados
  if (length(response_json$organic) == 0) {
    return(NULL)
  }
  
  results_df <- as.data.frame(response_json$organic)
  return(results_df)
}

# Definir a pasta onde os arquivos serão salvos
output_dir <- "downloads"
if (!dir.exists(output_dir)) {
  dir.create(output_dir)
}

# Loop sobre cada termo de busca
for (term in search_terms) {
  # Exibe o termo de busca atual
  print(paste("Buscando por:", term))
  
  # Buscar a primeira página para o termo de busca atual
  all_results <- fetch_first_page(term)
  
  # Paginação a partir da segunda página
  page_num <- 2
  
  repeat {
    results_df <- fetch_results(term, page_num)
    
    if (is.null(results_df)) {
      break
    }
    
    all_results <- bind_rows(all_results, results_df)
    page_num <- page_num + 1
  }
  
  # Iterar sobre cada link e tentar fazer o download de PDFs
  for (i in 1:nrow(all_results)) {
    link <- all_results$link[i]
    
    # Verificar se o link termina com .pdf
    if (grepl("\\.pdf$", link, ignore.case = TRUE)) {
      
      # Extrair o nome do arquivo da URL (após a última barra '/')
      file_name <- basename(link)
      file_path <- file.path(output_dir, file_name)
      
      # Tentar fazer o download do arquivo
      tryCatch({
        download.file(link, destfile = file_path, mode = "wb")
        if (file.exists(file_path)) {
          print(paste("Arquivo baixado com sucesso:", file_path))
        } else {
          print(paste("Falha ao baixar o arquivo:", link))
        }
      }, error = function(e) {
        print(paste("Erro ao baixar o arquivo:", link, "Erro:", e$message))
      }, warning = function(w) {
        print(paste("Aviso ao baixar o arquivo:", link, "Aviso:", w$message))
      })
    }
  }
}

